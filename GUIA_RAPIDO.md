# üöÄ Guia R√°pido - Sistema Modular

## ‚ö° Comandos Essenciais

### 1Ô∏è‚É£ Coleta de Reposit√≥rios

```bash
# B√°sico: 50 Rapid + 50 Slow
python 1_collect_repositories.py --rapid 50 --slow 50

# Grande escala: 100 Rapid + 100 Slow
python 1_collect_repositories.py --rapid 100 --slow 100 --max-search 2000

# Apenas Rapid
python 1_collect_repositories.py --rapid 100 --slow 0

# Apenas Slow
python 1_collect_repositories.py --rapid 0 --slow 100
```

---

### 2Ô∏è‚É£ An√°lise SonarQube

```bash
# Sequencial (1 por vez)
python 2_analyze_sonarqube.py

# Paralelo (4 workers) - RECOMENDADO
python 2_analyze_sonarqube.py --workers 4

# Apenas Rapid
python 2_analyze_sonarqube.py --type rapid --workers 4

# Apenas Slow
python 2_analyze_sonarqube.py --type slow --workers 4

# Pular j√° analisados (retomar)
python 2_analyze_sonarqube.py --skip-analyzed --workers 4

# Limitar an√°lises (teste)
python 2_analyze_sonarqube.py --limit 10 --workers 2
```

---

### 3Ô∏è‚É£ Consultar Dataset (Python)

```python
from dataset_manager import DatasetManager

dm = DatasetManager()

# Ver estat√≠sticas
dm.print_statistics()

# Listar todos
repos = dm.get_repositories()
print(f"Total: {len(repos)}")

# Filtrar por tipo
rapid = dm.get_repositories(release_type='rapid')
slow = dm.get_repositories(release_type='slow')

# Exportar CSV
dm.export_to_csv('meus_dados.csv')

# Verificar pendentes
dataset = dm.load_dataset()
pending = [r for r in dataset['repositories']
           if not r.get('sonarqube_analyzed', False)]
print(f"Faltam analisar: {len(pending)}")
```

---

### 4Ô∏è‚É£ Testar Sistema

```bash
# Testar filtros
python test_filters.py

# Testar dataset manager
python dataset_manager.py

# Exemplo completo
python example_usage.py
```

---

## üìä Workflow T√≠pico

### Dia 1: Coleta

```bash
python 1_collect_repositories.py --rapid 100 --slow 100 --max-search 2000
```

**Resultado:** `repositories_dataset.json` com ~200 reposit√≥rios

### Dia 2-5: An√°lise em Lotes

```bash
# Processar todos (recomendado - progresso organizado)
python 2_analyze_sonarqube.py --workers 4 --skip-analyzed

# Ou em lotes menores
python 2_analyze_sonarqube.py --workers 4 --limit 50 --skip-analyzed
python 2_analyze_sonarqube.py --workers 4 --limit 50 --skip-analyzed
# ... at√© completar todos
```

### Exportar Resultados

```python
from dataset_manager import DatasetManager
DatasetManager().export_to_csv('dataset_final.csv')
```

---

## üîç Verifica√ß√µes √öteis

### Ver status do dataset

```python
from dataset_manager import DatasetManager
dm = DatasetManager()
stats = dm.get_statistics()
print(f"Total: {stats['total']}")
print(f"Rapid: {stats['rapid']}, Slow: {stats['slow']}")
```

### Contar n√£o analisados

```python
from dataset_manager import DatasetManager
dm = DatasetManager()
dataset = dm.load_dataset()
not_analyzed = [r for r in dataset['repositories']
                if not r.get('sonarqube_analyzed', False)]
print(f"Pendentes: {len(not_analyzed)}")
```

### Listar reposit√≥rios pendentes

```python
from dataset_manager import DatasetManager
dm = DatasetManager()
dataset = dm.load_dataset()
pending = [r for r in dataset['repositories']
           if not r.get('sonarqube_analyzed', False)]

for i, repo in enumerate(pending, 1):
    print(f"{i}. {repo['full_name']} ({repo['release_type']})")
```

---

## ‚öôÔ∏è Configura√ß√£o Inicial

### 1. Arquivo .env

```bash
# GitHub (obrigat√≥rio para coleta)
GITHUB_TOKEN=seu_token_aqui

# SonarQube (obrigat√≥rio para an√°lise)
SONAR_HOST=http://localhost:9000
SONAR_TOKEN=seu_token_aqui

# PostgreSQL (opcional)
DB_HOST=localhost
DB_NAME=sonar
DB_USER=sonar
DB_PASSWORD=sonar
DB_PORT=5432
```

### 2. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

### 3. Iniciar Docker (para an√°lise)

```bash
docker-compose up -d
```

---

## üõ†Ô∏è Troubleshooting

### Erro: "Rate limit"

```bash
# Aguardar ou reduzir --max-search
python 1_collect_repositories.py --rapid 50 --slow 50 --max-search 500
```

### Erro: "Docker not found"

```bash
# Instalar Docker Desktop e iniciar
# https://www.docker.com/products/docker-desktop
```

### An√°lise travando

```bash
# Reduzir workers
python 2_analyze_sonarqube.py --workers 1

# Ou limitar quantidade
python 2_analyze_sonarqube.py --workers 2 --limit 10
```

### Re-analisar tudo

```python
# Marcar todos como n√£o analisados
from dataset_manager import DatasetManager
dm = DatasetManager()
dataset = dm.load_dataset()
for repo in dataset['repositories']:
    repo['sonarqube_analyzed'] = False
dm.save_dataset(dataset)
```

---

## üìÅ Arquivos Gerados

```
repositories_dataset.json  ‚Üí Dataset principal (JSON)
repositories_dataset.csv   ‚Üí Exporta√ß√£o CSV
test_dataset.json         ‚Üí Dataset de teste
example_dataset.json      ‚Üí Dataset do exemplo
```

---

## üéØ Dicas de Performance

### Coleta R√°pida

- Use `--max-search` menor para coletas r√°pidas
- Aumenta taxa de aprova√ß√£o: busque repos mais populares

### An√°lise R√°pida

- Use `--workers 4` em m√°quinas com 4+ cores
- Monitore uso de RAM (cada worker = reposit√≥rio clonado)
- Em SSDs, an√°lise √© mais r√°pida

### Economia de API Calls

- Dataset evita re-buscar mesmos repos
- Use `--skip-analyzed` para retomar
- GitHub API: 5000 calls/hora (com token)

---

## üìû Ajuda

```bash
# Ajuda do Script 1
python 1_collect_repositories.py --help

# Ajuda do Script 2
python 2_analyze_sonarqube.py --help
```

---

**√öltima atualiza√ß√£o:** 19/10/2025  
**Vers√£o:** 2.0
